{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "vis_dir = '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/train'\n",
    "input_dirs = {\n",
    "    'train': '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/train',\n",
    "    'validation': '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation',\n",
    "    'test': '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/test'\n",
    "}\n",
    "output_dir = '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/processed'\n",
    "\n",
    "for subset in input_dirs.keys():\n",
    "    subset_dir = os.path.join(output_dir, subset)\n",
    "    if not os.path.exists(subset_dir):\n",
    "        os.makedirs(subset_dir)\n",
    "\n",
    "def apply_contour(input_path):\n",
    "    img = cv2.imread(input_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def apply_blur(input_path, blur_type='gaussian'):\n",
    "    img = cv2.imread(input_path)\n",
    "    if blur_type == 'gaussian':\n",
    "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    elif blur_type == 'median':\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "    return img\n",
    "\n",
    "def apply_hist_eq(input_path):\n",
    "    img = cv2.imread(input_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    eq_img = cv2.equalizeHist(gray)\n",
    "    return eq_img\n",
    "\n",
    "def apply_edge_enhancement(input_path):\n",
    "    img = cv2.imread(input_path)\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) \n",
    "    sharpened = cv2.filter2D(img, -1, kernel)\n",
    "    return sharpened\n",
    "\n",
    "def resize_and_save_image(input_path, output_path, size=(128, 128)):\n",
    "    try:\n",
    "        with Image.open(input_path) as img:\n",
    "            if img.mode == 'P':\n",
    "                img = img.convert('RGBA')\n",
    "            if img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info):\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            img_array = np.array(img) \n",
    "            img_array = apply_contour(input_path)  \n",
    "            img_array = apply_blur(input_path)   \n",
    "            img_array = apply_hist_eq(input_path)  \n",
    "            img_array = apply_edge_enhancement(input_path)  \n",
    "\n",
    "            img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            img = Image.fromarray(img_array)\n",
    "            img = img.resize(size, Image.LANCZOS)\n",
    "            img.save(output_path, format='JPEG')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_path}: {e}\")\n",
    "\n",
    "def process_directory(input_directory, output_directory):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        relative_path = os.path.relpath(root, input_directory)\n",
    "        output_path = os.path.join(output_directory, relative_path)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                input_file_path = os.path.join(root, file_name)\n",
    "                output_file_path = os.path.join(output_path, file_name)\n",
    "                resize_and_save_image(input_file_path, output_file_path)\n",
    "\n",
    "for subset, dir_path in input_dirs.items():\n",
    "    process_directory(dir_path, os.path.join(output_dir, subset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3114 images belonging to 36 classes.\n",
      "Found 359 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_dir = '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/processed/train'\n",
    "test_dir = '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/processed/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    seed=777,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "import json\n",
    "with open('class_indices.json', 'w') as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    seed=777,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    '/content/processed/best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),  \n",
    "\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), \n",
    "    layers.Dense(36, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_callback, lr_scheduler, early_stopping]\n",
    ")\n",
    "\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Results:\n",
      "Image: /home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/corn/Image_7.jpg\n",
      "Predicted Class: sweetcorn\n",
      "True Class: corn\n",
      "\n",
      "Image: /home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/cabbage/Image_6.jpg\n",
      "Predicted Class: cabbage\n",
      "True Class: cabbage\n",
      "\n",
      "Image: /home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/paprika/Image_10.jpg\n",
      "Predicted Class: paprika\n",
      "True Class: paprika\n",
      "\n",
      "Image: /home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/orange/Image_10.png\n",
      "Predicted Class: orange\n",
      "True Class: orange\n",
      "\n",
      "Image: /home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/orange/cam.jpg\n",
      "Predicted Class: orange\n",
      "True Class: orange\n",
      "\n",
      "Image: /home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/ginger/gung.jpg\n",
      "Predicted Class: ginger\n",
      "True Class: ginger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model = tf.keras.models.load_model('/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/best_model.keras')\n",
    "\n",
    "image_paths = [\n",
    "    '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/corn/Image_7.jpg',\n",
    "    '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/cabbage/Image_6.jpg',\n",
    "    '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/paprika/Image_10.jpg',\n",
    "    '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/orange/Image_10.png',\n",
    "    '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/orange/cam.jpg',\n",
    "    '/home/leo/workspace/Personal_Project/Children_Vision/models/images_classification/validation/ginger/gung.jpg'\n",
    "]\n",
    "\n",
    "def get_true_label(img_path):\n",
    "    return os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128)) \n",
    "    img_array = image.img_to_array(img)  \n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    img_array = img_array / 255.0 \n",
    "    return img_array\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    pred_prob = model.predict(img_array)\n",
    "    pred_class = np.argmax(pred_prob, axis=1)[0]  \n",
    "    predictions.append(pred_class)\n",
    "    true_labels.append(get_true_label(img_path))  \n",
    "\n",
    "label_names = {v: k for k, v in test_generator.class_indices.items()}\n",
    "\n",
    "print(\"Results:\")\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    pred_label = label_names[predictions[i]]\n",
    "    true_label = true_labels[i]\n",
    "    print(f\"Image: {img_path}\")\n",
    "    print(f\"Predicted Class: {pred_label}\")\n",
    "    print(f\"True Class: {true_label}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
